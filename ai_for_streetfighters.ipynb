{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AIForStreetFighters.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "name": "_merged"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deokdecef44cnsnddos9ndam/ml-security/blob/master/ai_for_streetfighters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaRDBY2hoksK",
        "colab_type": "text"
      },
      "source": [
        "# Section 0: Intro to Notebooks\n",
        "For more information, see the introduction to colab [linked here.](https://colab.research.google.com/notebooks/intro.ipynb#scrollTo=gJr_9dXGpJ05)\n",
        "\n",
        "Notebooks are a way of organizing code blocks and text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxSppYbcpOYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 0.0.0\n",
        "\n",
        "# Code Blocks will contain a \"play\" button to the right of them. Pressing play\n",
        "# will execute the code they contain and modify the program state.\n",
        "i = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPqSzFd2p-6A",
        "colab_type": "text"
      },
      "source": [
        "Blocks that are just text are just for illustrative purposes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUByrloyqMYt",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@markdown 0.0.1\n",
        "\n",
        "#@markdown Some code blocks will be hidden behind text. These should contain a reference to the fact that they can be executed. If not, just look for the play button or the numbered marking.\n",
        "\n",
        "print(f\"Executed Code, i is currently {i}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkFbAUjcpPVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 0.0.2\n",
        "\n",
        "# Code Blocks can be executed more than once. \n",
        "i += 1\n",
        "print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UZBvpNopRJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0.0.3\n",
        "\n",
        "# Code Blocks can be executed in any order, but this notebook is designed to be\n",
        "# run sequentially\n",
        "i *=2\n",
        "print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EetFSORbpSM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0.0.4\n",
        "\n",
        "# You can also use <shift> <enter> to execute a block\n",
        "print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMjIlzOeraNC",
        "colab_type": "text"
      },
      "source": [
        "If you run into any problems working through the notebook, reach out in the meeting chat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y-mCekno8Gq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# Section 1: Making a Model\n",
        "This section will walk you through the process of creating a classifier that can recognize handwritten digits. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu-dDjYPowWL",
        "colab_type": "text"
      },
      "source": [
        "## 1.0 Setup\n",
        "First, we need to load some libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hP0Kp7lUGhae",
        "colab": {}
      },
      "source": [
        "# 1.0.0\n",
        "\n",
        "!git clone https://deokdecef44cnsnddos9ndam-r:aQ05%244H%25n2eaBVWFPPgB@github.com/deokdecef44cnsnddos9ndam/ml-security.git mlsec > /dev/null 2>&1\n",
        "!pip install --no-deps kornia > /dev/null 2>&1\n",
        "!pip install pretrainedmodels scikit-image > /dev/null 2>&1\n",
        "\n",
        "# Machine Learning Library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Plotting Libraries\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as display\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Custom Libraries for demos\n",
        "import mlsec.mnist\n",
        "import mlsec.imagenet\n",
        "import mlsec.plots\n",
        "import mlsec.utils\n",
        "\n",
        "sns.set()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzkrkupQIGIG",
        "colab_type": "text"
      },
      "source": [
        "Lets make sure there are GPU's available. If the following block fails, select Runtime > Change Runtime Type and select GPU from the dropdown menu. Then Runtime > Factory Reset Runtime and start executing code blocks from the beginning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nUiSdhboC15M",
        "colab": {}
      },
      "source": [
        "# 1.0.1\n",
        "assert torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrtK5YFQRhar",
        "colab_type": "text"
      },
      "source": [
        "## 1.1: The Dataset\n",
        "\n",
        "Next, we will load a dataset of [images containing handwritten digits.](http://yann.lecun.com/exdb/mnist/) Each image in the dataset is a 28x28 black and white image and has a matching label (0-9) that tells us which digit is in the image. These labels will be used to provide feedback to the model and to automatically evaluate its performance.\n",
        "\n",
        "The dataset is split up into two parts: one for training and one for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7SQTLrmRWp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1.1.1\n",
        "training_set = mlsec.mnist.get_training_data(device)\n",
        "testing_set = mlsec.mnist.get_testing_data(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27aV15DkRndO",
        "colab_type": "text"
      },
      "source": [
        "## 1.3: Visualize digit data\n",
        "\n",
        "Let's get familiar with the handwritten digit dataset, so we understand the task our model will need to undertake. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKNC3R9etZZL",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@markdown 1.3.0\n",
        "\n",
        "#@markdown Lets look at a random image and its corresponding label.\n",
        "examples, example_labels = mlsec.mnist.get_examples(testing_set)\n",
        "\n",
        "import numpy as np\n",
        "example_button = widgets.Button(description=\"Get Another\")\n",
        "example_img = None\n",
        "example_label = None\n",
        "\n",
        "def view_random_inference(*args, **kwargs):\n",
        "  plt.close()\n",
        "  display.clear_output(wait=True)\n",
        "  rand_idx = np.random.choice(len(examples))\n",
        "  global example_img\n",
        "  global example_label\n",
        "  example_img = examples[rand_idx].unsqueeze(0)\n",
        "  example_label = example_labels[rand_idx]\n",
        "\n",
        "  probs = torch.zeros((1, 10))\n",
        "  mlsec.plots.example(example_img, probs, example_label)\n",
        "  plt.title(\"\")\n",
        "  display.display(example_button)\n",
        "\n",
        "example_button.on_click(view_random_inference)\n",
        "\n",
        "view_random_inference()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coontAIfRoAn",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@markdown 1.3.1\n",
        "\n",
        "#@markdown Run this code block to visualize many examples from the dataset at once. \n",
        "\n",
        "#@markdown You'll notice that there are a variety of different handwriting styles and stroke widths. It's good for the dataset that the model learns from to have sufficient variety, so that the model will hopefully generalize to other unseen handwriting styles.\n",
        "\n",
        "mlsec.utils.image_grid(examples, 20, (20, 20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MVkcWbxchTor"
      },
      "source": [
        "## 1.4: Initialize the digit classification model\n",
        "The digit classifier is our mixing console--a system with a complex series of operations that can take a high dimensional input, and when its \"knobs\" are turned just right, produces the desired output.\n",
        "\n",
        "We want our classifier to identify which digit is depicted in a black and white image. We will use a powerful type of model called a convolutional neural network. There are many possible ways to construct a convolutional network. The important thing for our purposes is that it takes an image as input, has a sequence of operations whose \"knobs\" or parameters can be tuned, and has the correct number of outputs, 10 for the digits 0 through 9.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IPlTVcF2M5nv",
        "colab": {}
      },
      "source": [
        "# 1.4.0\n",
        "\n",
        "model = mlsec.mnist.build_model(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTqELKxTefnv",
        "colab_type": "text"
      },
      "source": [
        "## 1.5: Pre-test our our model\n",
        "\n",
        "Let's try out our randomly initialized model. If we feed it a 28x28 image of a handwritten digit, we get out 10 confidence scores, one for each possible digit, 0-9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "yQ3vkKoTFZP7",
        "colab": {}
      },
      "source": [
        "#@markdown 1.5.0\n",
        "\n",
        "#@markdown Run this code block to view the outputs of the model for random sample images from the dataset. \n",
        "\n",
        "#@markdown You'll notice that the model is equally unconfident in every digit. This is because our model's \"knobs\" started out pointing in random directions. It hasn't learned anything about what different digits look like yet.\n",
        "\n",
        "import numpy as np\n",
        "example_button = widgets.Button(description=\"Get Another\")\n",
        "example_img = None\n",
        "example_label = None\n",
        "\n",
        "def view_random_inference(*args, **kwargs):\n",
        "  plt.close()\n",
        "  display.clear_output(wait=True)\n",
        "  rand_idx = np.random.choice(len(examples))\n",
        "  global example_img\n",
        "  global example_label\n",
        "  example_img = examples[rand_idx].unsqueeze(0)\n",
        "  example_label = example_labels[rand_idx]\n",
        "\n",
        "  probs = model(example_img.cuda()).cpu()\n",
        "  mlsec.plots.example(example_img, probs, example_label)\n",
        "  display.display(example_button)\n",
        "\n",
        "example_button.on_click(view_random_inference)\n",
        "\n",
        "view_random_inference()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF3kGy41ujxB",
        "colab_type": "text"
      },
      "source": [
        "Our model's outputs are bad, but just how bad?\n",
        "\n",
        "The obvious way to evaluate them is using the test set. We will take the highest confidence output as the model's predicition and track the percentage of the time this corresponds with the true label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0jgpZ2GSy82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1.5.1\n",
        "\n",
        "mlsec.mnist.run_test(model, testing_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdKiAssnu50A",
        "colab_type": "text"
      },
      "source": [
        "This gives us a good picture of how this model might perform in aggregate, but it does not give us much clarity on how bad an individual prediction might be. For that, we use something called a **loss function**. This will give us a nice continuous score we can use to evaluate the model's outputs. You can think of the loss as the distance to the correct prediction.\n",
        "\n",
        "The exact details of how this loss is implemented is not super important, so feel free to just skim over it. The important thing to know is that it is minimized when the model outputs full confidence in the provided label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEmWBQdAbU01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1.5.2\n",
        "\n",
        "def loss_fn(probs, label):\n",
        "  # Convert probs to log probs\n",
        "  log_probs = torch.log(probs)\n",
        "  # Get the log probs for the specified class labels\n",
        "  log_probs = log_probs.gather(-1, label.unsqueeze(-1))\n",
        "  # Return the negative mean\n",
        "  return -1 * log_probs.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RruqNsnbbhjI",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@markdown 1.5.3\n",
        "\n",
        "#@markdown To get a little more intuition for how the loss provides feed back to the model output, lets pretend we are the model.\n",
        "#@markdown The sliders correspond to our raw confidence outputs for each of the classes. \n",
        "\n",
        "#@markdown Minimize the loss by adjusting the sliders. Pay attention to the scaling of the loss.\n",
        "\n",
        "import random\n",
        "sample_image = torch.load('mlsec/images/3.pt').to(device)\n",
        "\n",
        "def update(*args, **kwargs):\n",
        "  slider_values  = torch.tensor([s.value for s in sliders])\n",
        "  probs = slider_values / torch.sum(slider_values)\n",
        "  loss_history.append(loss_fn(probs.view(-1, 10), mlsec.mnist.make_label(3, torch.device('cpu'))))\n",
        "  mlsec.plots.progress_no_inference(sample_image, probs.view(-1, 10), loss_history, 3)\n",
        "  display.clear_output(wait=True)\n",
        "  display.display(widgets.Box(sliders))\n",
        "\n",
        "def make_slider(i):\n",
        "  s = widgets.FloatSlider(\n",
        "    value=10 * random.random(),\n",
        "    min=0,\n",
        "    max=10.0,\n",
        "    step=0.1,\n",
        "    description=f'{i}',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='vertical',\n",
        "    readout=True,\n",
        "    readout_format='.1f',\n",
        "  )\n",
        "  s.observe(update, names='value')\n",
        "  return s\n",
        "\n",
        "sliders = [make_slider(i) for i in range(10)]\n",
        "loss_history = []\n",
        "\n",
        "update()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ifToLt0eUpl",
        "colab_type": "text"
      },
      "source": [
        "## 1.6: Train the model\n",
        "\n",
        "Now we have most of the components we need to train our model: a labeled dataset and a model with many tunable parameters. But how do we use the dataset to train the model?\n",
        "\n",
        "We want to be able to assess how well our classifier works on handwritten digits and provide it feedback on how to improve.\n",
        "Instead of relying on the finely tuned ear of a professional audio engineer to tell us when the mix is \"just right,\" we will do this in an automated way so that the model can learn directly from the data.\n",
        "\n",
        "Using our machine learning libraries and a process called backpropagation, we can compute the direction we need to move each of our parameters to decrease the loss for a given image and label.\n",
        "By repeatedly showing the model many handwritten digit images, computing the loss, and incrementally updating the model's parameters, the model slowly gets better at identifying digits.\n",
        "\n",
        "This next block will show how we update the parameters based on the loss. Again, the details are not super important. To continue with the metaphor, the `p.grad` is telling us the direction in which we need to update our \"knobs\" and the `learning_rate` is the amount that we are turning them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC6EYvlo1D0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1.6.0\n",
        "\n",
        "def update_parameters(loss, parameters, learning_rate=5E-2):\n",
        "  # Set our parameters .grad in the direction that will decrease the loss\n",
        "  loss.backward()\n",
        "  # For all of our specified parameters...\n",
        "  for p in parameters:\n",
        "    # Turn the knob slightly in the direction that will decrease our loss\n",
        "    p.data = p.data - learning_rate * p.grad\n",
        "    # Reset the grad data for the next evaluation\n",
        "    p.grad = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyhnkM9iXWit",
        "colab_type": "text"
      },
      "source": [
        "This is all we need to train our neural net. Let's see how it does. We will  watch how the model reacts to an example digit (left) by plotting its confidence scores (center) as it is trained. We also plot the loss over time (right). We are hoping to see the model becoming confident in the correct class for our sample digit, and see the loss steadily decrease over time to near 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Byjwpc21GPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1.6.1\n",
        "\n",
        "loss_history = []\n",
        "sample_image = torch.load('mlsec/images/3.pt').to(device)\n",
        "\n",
        "for epoch in range(4):\n",
        "  for batch_num, (data, labels) in enumerate(training_set):\n",
        "    \n",
        "    # Get the model outputs \n",
        "    output_confidences = model(data)\n",
        "    # Compute the loss with respect to the ground truth labels\n",
        "    loss = loss_fn(output_confidences, labels.to(device))\n",
        "    # Update the model parameters\n",
        "    update_parameters(loss, model.parameters())\n",
        "    # Repeat...\n",
        "\n",
        "    # Plotting code (ignore)\n",
        "    loss_history.append(loss.item())\n",
        "    if (epoch == 0 and batch_num < 100) or batch_num % 100 == 0:\n",
        "      mlsec.plots.progress(sample_image, model, loss_history, 3)\n",
        "\n",
        "display.clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFLq62CVKIPy",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown 1.6.2\n",
        "\n",
        "#@markdown Now, we can rerun our model on samples from the test set to see how its inferences have changed. It should be almost always entirely confident in the correct class. \n",
        "\n",
        "#@markdown Look for wrong or misclassified examples. Do you agree with the model or label? Do you understand why the model had trouble with this example?\n",
        "example_button = widgets.Button(description=\"Get Another\")\n",
        "example_img = None\n",
        "example_label = None\n",
        "\n",
        "def view_random_inference(*args, **kwargs):\n",
        "  plt.close()\n",
        "  display.clear_output(wait=True)\n",
        "  rand_idx = np.random.choice(len(examples))\n",
        "  global example_img\n",
        "  global example_label\n",
        "  example_img = examples[rand_idx].unsqueeze(0)\n",
        "  example_label = example_labels[rand_idx]\n",
        "\n",
        "  probs = model(example_img.cuda()).cpu()\n",
        "  mlsec.plots.example(example_img, probs, example_label)\n",
        "  display.display(example_button)\n",
        "\n",
        "example_button.on_click(view_random_inference)\n",
        "\n",
        "view_random_inference()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xgcpb2Jmhzb",
        "colab_type": "text"
      },
      "source": [
        "## 1.7: Evaluate our model on a held out test set\n",
        "\n",
        "During training, we saw that our model became highly confident on a sample digit, and the loss went down steadily. But how do we know how good our classifier is, and how do we know it didn't \"cheat\" and simply memorize all of the examples we showed it?\n",
        "\n",
        "This is why we maintain a seperate test set. It allows us to test how the model will perform on samples it has never seen before. This property is called **generalization.** If accuracy on this held out set is high, it means our classifier successfully generalizes to new unseen handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZdoulkwPH6WQ",
        "colab": {}
      },
      "source": [
        "# 1.7.0\n",
        "mlsec.mnist.run_test(model, testing_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipx-j38VpHfU",
        "colab_type": "text"
      },
      "source": [
        "## 1.8: Interact with your trained digit classifier\n",
        "\n",
        "Now that we have trained a classifier and verified that it works well on a held out test set, we can use it recognize our own handwriting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "m2JRt6byHNAx",
        "colab": {}
      },
      "source": [
        "#@markdown 1.8.0\n",
        "\n",
        "#@markdown Try running this code block and drawing a digit in the box below. When you're done, hit \"finish\" and you'll see what your classifier thinks you wrote. Hit \"Try Again\" to restart.\n",
        "\n",
        "#@markdown Take a few minutes to interact with your classifier. \n",
        "\n",
        "#@markdown Does it work as you expected? Are there any common error cases? Some digits that are commonly confused?\n",
        "\n",
        "#@markdown Can you consistently write a valid digit that your classifier gets wrong? How?\n",
        "\n",
        "Does it work as you expected? Are there any common error cases? Some digits that are commonly confused?\n",
        "\n",
        "Can you write a valid digit that your classifier gets wrong?\n",
        "Does it work as you expected? Are there any common error cases? Some digits that are commonly confused?\n",
        "\n",
        "Can you write a valid digit that your classifier gets wrong?\n",
        "\n",
        "#adapted from https://gist.github.com/korakot/8409b3feec20f159d8a50b0a811d3bca\n",
        "\n",
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import kornia\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<canvas width=%d height=%d style=\"border:1px solid #000000;\"></canvas>\n",
        "<button>Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "ctx.lineWidth = %d\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "import base64\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "def draw(w=280, h=280, line_width=20):\n",
        "  display.display(HTML(canvas_html % (w, h, line_width)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  numpy_img = np.array(Image.open(BytesIO(binary)))\n",
        "  numpy_img = numpy_img[:, :, 3] / 255.0\n",
        "  torch_img = torch.FloatTensor(numpy_img)\n",
        "  torch_img = torch_img.view(1, 1, 280, 280)\n",
        "  torch_img = kornia.resize(torch_img, (28, 28))\n",
        "  torch_img = mlsec.mnist.Binarize()(torch_img)\n",
        "  return torch_img\n",
        "\n",
        "button = widgets.Button(description=\"Try Again\")\n",
        "display.display(button)\n",
        "\n",
        "def show_example_inference(arg):\n",
        "  display.clear_output(wait=True)\n",
        "  digit = draw()\n",
        "  display.clear_output(wait=True)\n",
        "  mlsec.plots.example(digit, model(digit.cuda()), None)\n",
        "  display.display(button, wait=True)\n",
        "\n",
        "button.on_click(show_example_inference)\n",
        "\n",
        "show_example_inference(None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kQiuxAtCFoOv"
      },
      "source": [
        "# Section 2: Basics of Adversarial Machine Learning\n",
        "\n",
        "Before, we tried to hand craft valid examples that our model misclassified. Adversarial machine learning is the process of generating these kinds of examples automatically. \n",
        "\n",
        "# Section 2.1: Optimizing the Image\n",
        "\n",
        "When we were training our model, we were using the parameters of the model as our \"knobs.\" One of the key insights of generating adversarial examples is that our image is also just a set of knobs that we can tune the same way. \n",
        "\n",
        "For example, lets compute the loss for a sample image and its label and then update the parameters of the image to decrease that loss. To do so, we can re-use the exact same functions we used to train the model, but replace `model.parameters()` with our image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UyWFUKv6GdVA",
        "colab": {}
      },
      "source": [
        "# 2.1.0\n",
        "\n",
        "# Specifying that our image is now a optimizable parameter, or \"knob\"\n",
        "image = nn.Parameter(sample_image)\n",
        "\n",
        "# Get the correct label for our image, a 3\n",
        "label = mlsec.mnist.make_label(3, device)\n",
        "\n",
        "# Compute the loss with our model and label\n",
        "loss = loss_fn(model(image), label)\n",
        "print(f'Loss before updating the image: {loss.item()}')\n",
        "\n",
        "# Perform an update step minimizing the loss, but update the image parameters this time\n",
        "update_parameters(loss, [image])\n",
        "\n",
        "# Re-evaluate the loss on our new image\n",
        "loss = loss_fn(model(image), label)\n",
        "print(f'Loss after updating the image: {loss.item()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMSouVYCn62F",
        "colab_type": "text"
      },
      "source": [
        "What if instead of updating the image towards the true label, we tried to update it towards another random label?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng49WIGOn4XX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2.1.1\n",
        "\n",
        "# Get a label of a different class, 7\n",
        "fake_label = mlsec.mnist.make_label(7, device)\n",
        "\n",
        "# Compute the loss with this new fake label\n",
        "loss = loss_fn(model(image), fake_label)\n",
        "print(f'Loss before updating the image: {loss.item()}')\n",
        "\n",
        "# Update our parameters to minimize this new loss\n",
        "update_parameters(loss, [image])\n",
        "\n",
        "# Re-evaluate the loss with our new parameters\n",
        "loss = loss_fn(model(image), fake_label)\n",
        "print(f'Loss after updating the image: {loss.item()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHMMlQnIsfkj",
        "colab_type": "text"
      },
      "source": [
        "The loss is much higher, but everything still works. There is no requirement that our labels need to be genuine. This is the second key insight in creating your first adversarial example. We can optimize the image to make the model behave however we like. \n",
        "\n",
        "## Section 2.2: Carrying Out A Simple Attack\n",
        "\n",
        "What if we keep repeating this process for our hand picked incorrect label?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vk0DO9qsKthg",
        "colab": {}
      },
      "source": [
        "# 2.2.0\n",
        "\n",
        "# Specifying that our image is now a optimizable parameter, or \"knob\"\n",
        "image = nn.Parameter(sample_image)\n",
        "\n",
        "loss_history = []\n",
        "for iteration in range(100):\n",
        "  # Get the current confidence outputs for the iamge\n",
        "  output_confidence = model(image)\n",
        "  # Compute the loss with the adversarial label\n",
        "  loss = loss_fn(output_confidence, fake_label)\n",
        "  # Update the image to minimize this new loss\n",
        "  update_parameters(loss, [image])\n",
        "\n",
        "  # Plotting code\n",
        "  loss_history.append(loss.item())\n",
        "  mlsec.plots.progress(image, model, loss_history, 7)\n",
        "\n",
        "display.clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpJsMS96x4h4",
        "colab_type": "text"
      },
      "source": [
        "We now have an image that should visually appear to be a 3, but is a high confidence prediction of the class 7. Congratulations, you have successfully carried out an adversarial attack."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfnsxv2P6w9y",
        "colab_type": "text"
      },
      "source": [
        "## Section 3: Towards Real World Attacks\n",
        "\n",
        "Now that we've walked through the process of creating a simple adversarial attack in the digital realm, lets look at the process for creating physical attacks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sWdsvlvkN24y"
      },
      "source": [
        "## Section 3.1: ImageNet\n",
        "\n",
        "First, lets load up a more real world model. For our example model, we will be using [resnet18](https://arxiv.org/abs/1512.03385) pretrained on ImageNet. ImageNet is a classification dataset much like the dataset we used to train our model. Instead of black and white digits, it is designed to take natural images as its input. It has 1000 classes covering many different kinds of common objects.\n",
        "\n",
        "Lets initialize our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "08VTm5iANvf8",
        "colab": {}
      },
      "source": [
        "# 3.1.0\n",
        "\n",
        "model = mlsec.imagenet.build_model(\"resnet18\", device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z8Vf_4FfOCX7"
      },
      "source": [
        "Since this model has already been trained, we can load up images and view their inferences right away.\n",
        "\n",
        "We are using a pre-trained model because training an ImageNet model takes hours and significant compute resources. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Kos2HxEN_ds",
        "colab": {}
      },
      "source": [
        "# 3.1.1\n",
        "\n",
        "# Load Toaster Image\n",
        "toaster = mlsec.utils.load_image_as_tensor('mlsec/images/toaster.jpg')\n",
        "# Get the model outputs for the toaster image\n",
        "probs = model(toaster)\n",
        "# Plotting Code\n",
        "mlsec.plots.example(toaster, probs, 'toaster')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQywy6X8hcxk",
        "colab_type": "text"
      },
      "source": [
        "## Section 3.2: Attacking our ImageNet Model\n",
        "\n",
        "Although the datasets are very different, this model works exactly the same as the classifier we just made. Its taking an image as its input and outputing its confidences over the its classes.\n",
        "\n",
        "This means we can use the exact same `loss_fn` and `update_parameters` functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fw2u-oa0OmBG",
        "colab": {}
      },
      "source": [
        "# 3.2.0\n",
        "\n",
        "# Specifying that our image is now a optimizable parameter, or \"knob\"\n",
        "image = nn.Parameter(toaster)\n",
        "\n",
        "# Get the correct label for our image, toaster\n",
        "label = mlsec.imagenet.make_label('toaster', device)\n",
        "\n",
        "# Compute the loss with our model and label\n",
        "loss = loss_fn(model(image), label)\n",
        "print(f'Loss before updating the image: {loss.item()}')\n",
        "\n",
        "# Perform an update step minimizing the loss, but update the image parameters this time\n",
        "update_parameters(loss, [image])\n",
        "\n",
        "# Re-evaluate the loss on our new image\n",
        "loss = loss_fn(model(image), label)\n",
        "print(f'Loss after updating the image: {loss.item()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShNWSBMEh-UK",
        "colab_type": "text"
      },
      "source": [
        "Which also means we can carry out the exact same kind of attack."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QJbb9ltAPbsw",
        "colab": {}
      },
      "source": [
        "# 3.2.1\n",
        "\n",
        "# Specifying that our image is now a optimizable parameter, or \"knob\"\n",
        "image = nn.Parameter(toaster)\n",
        "# Creating a fake label for the class 'corn'\n",
        "fake_label = mlsec.imagenet.make_label('corn', device)\n",
        "\n",
        "loss_history = []\n",
        "for epoch in range(15):\n",
        "  # Get the current confidence outputs for the image\n",
        "  output_confidence = model(image)\n",
        "  # Compute the loss with the adversarial label\n",
        "  loss = loss_fn(output_confidence, fake_label)\n",
        "  # Update the image to minimize this new loss\n",
        "  update_parameters(loss, [image])\n",
        "\n",
        "  # Plotting code\n",
        "  loss_history.append(loss.item())\n",
        "  mlsec.plots.progress(image, model, loss_history, 'corn')\n",
        "\n",
        "display.clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8FybsABuS07T",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown 3.2.2\n",
        "\n",
        "#@markdown Looking at our progress plot above, it does not seem like the image changed much. Let's look closer. \n",
        "\n",
        "#@markdown You might be able to see some slight differences, but not by much.\n",
        "\n",
        "#@markdown A larger image in full color means we have many more knobs that we can turn. This leads to more ways in which\n",
        "#@markdown the model can fail, making it \"easier\" to find adversarial examples. This is partly why the example is far less perceptable.\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(20,10))\n",
        "mlsec.utils.show_on_axis(ax1, toaster, \"Before\")\n",
        "mlsec.utils.show_on_axis(ax2, image, \"After\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8F-F26E14zu",
        "colab_type": "text"
      },
      "source": [
        "## Section 3.3: Expectation Over Transformation\n",
        "\n",
        "We want things to work in the real world, which means we wont always be able to control how our adversarial attack is imaged. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97FSsFopCB40",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown 3.3.0\n",
        "\n",
        "#@markdown Lets see what happens if our adversarial image is slightly rotated.\n",
        "\n",
        "#@markdown You'll notice that it effectively never works. \n",
        "#@markdown Unless we can count on being able to perfectly control the pixels as they are captured, we need to find a way to encourage our examples to be robust to these real world transformations.\n",
        "\n",
        "example_button = widgets.Button(description=\"Try Again\")\n",
        "\n",
        "def view_random_inference_imagenet(*args, **kwargs):\n",
        "  plt.close()\n",
        "  global image\n",
        "  display.clear_output(wait=True)\n",
        "  transform_image = kornia.rotate(image, torch.rand(1) * 10.0 - 5.0)\n",
        "  probs = model(transform_image.cuda()).cpu()\n",
        "  mlsec.plots.example(transform_image, probs, 'corn')\n",
        "  display.display(example_button)\n",
        "\n",
        "example_button.on_click(view_random_inference_imagenet)\n",
        "\n",
        "view_random_inference_imagenet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UAtCqmKT4xhH"
      },
      "source": [
        "Much like training our classifier on a bunch of handwriting styles, to make our example generalize we need to train it on a bunch of transformation styles.\n",
        "\n",
        "Lets load a function that will randomly simulate real world transformations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7EUePYtS2uxi",
        "colab": {}
      },
      "source": [
        "# 3.3.1\n",
        "\n",
        "real_world_transform = mlsec.imagenet.get_transform()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "frDv82CTXpJc",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown 3.3.2\n",
        "\n",
        "#@markdown We can put our natural toaster image through these transformations to visualize their effect. \n",
        "\n",
        "#@markdown You'll notice that our natural image is fairly robust to these kinds of transformations. This is how we would like our attack to behave.\n",
        "\n",
        "example_button = widgets.Button(description=\"Try Again\")\n",
        "\n",
        "def view_random_transform(*args, **kwargs):\n",
        "  plt.close()\n",
        "  global toaster\n",
        "  global real_world_transform\n",
        "  display.clear_output(wait=True)\n",
        "  transform_image = real_world_transform(image, 1)\n",
        "  probs = model(transform_image.cuda()).cpu()\n",
        "  mlsec.plots.example(transform_image, probs, 'toaster')\n",
        "  display.display(example_button)\n",
        "\n",
        "example_button.on_click(view_random_transform)\n",
        "\n",
        "view_random_transform()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YQKvdJDTYfkx"
      },
      "source": [
        "As you can see, these kinds of transformations are trying to simulate what would happen if we tried to physically place our adversarial toaster image in front of the camera. These sorts of attacks are refered to as [**adversarial patches**](https://arxiv.org/pdf/1712.09665.pdf). \n",
        "\n",
        "To incorporate these transformations into our training set, we just pretend they are a random batch of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hx4AEINkZ0pW",
        "colab": {}
      },
      "source": [
        "# 3.3.3\n",
        "\n",
        "# Specifying that our image is now a optimizable parameter, or \"knob\"\n",
        "image = nn.Parameter(toaster)\n",
        "# Define the number of images we want to sample as a \"batch\"\n",
        "batch_size = 16\n",
        "# Creating a fake label for the class 'corn'\n",
        "fake_label = mlsec.imagenet.make_labels('corn',  batch_size, device)\n",
        "\n",
        "loss_history = []\n",
        "for _ in range(100):\n",
        "  # Sampling a \"batch\" of images from our transform\n",
        "  images = real_world_transform(image, batch_size)\n",
        "  # Get the current confidence outputs for the image\n",
        "  output_confidence = model(images)\n",
        "  # Compute the loss with the adversarial label\n",
        "  loss = loss_fn(output_confidence, fake_label)\n",
        "  # Update the image to minimize this new loss\n",
        "  update_parameters(loss, [image])\n",
        "\n",
        "  # Plotting code\n",
        "  loss_history.append(loss.item())\n",
        "  mlsec.plots.progress(images[0].unsqueeze(0), model, loss_history, 'corn')\n",
        "\n",
        "display.clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJml5XlZbXff",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown 3.3.3\n",
        "\n",
        "#@markdown Now lets see how robust this attack is.\n",
        "\n",
        "#@markdown It will not be perfect, but it should be much better than when we trained without these transfomations.\n",
        "\n",
        "example_button = widgets.Button(description=\"Try Again\")\n",
        "\n",
        "def view_random_transform(*args, **kwargs):\n",
        "  plt.close()\n",
        "  global image\n",
        "  global real_world_transform\n",
        "  display.clear_output(wait=True)\n",
        "  transform_image = real_world_transform(image, 1)\n",
        "  probs = model(transform_image.cuda()).cpu()\n",
        "  mlsec.plots.example(transform_image, probs, 'corn')\n",
        "  display.display(example_button)\n",
        "\n",
        "example_button.on_click(view_random_transform)\n",
        "\n",
        "view_random_transform()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9dizGSV0dQxU"
      },
      "source": [
        "We can evaluate the performance of this example by randomly sampling transformations and seeing how many of them reach some threshold criteria. For this evaluation, we'll consider a succesful attack generating a classification in the targeted class, `corn`, with a confidence above 50%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BrL-EZPdcsq7",
        "colab": {}
      },
      "source": [
        "# 3.3.4\n",
        "\n",
        "mlsec.plots.evaluate(model, real_world_transform, image, 'corn', threshold=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
